\documentclass{article}

\input{../preamble.tex}

\begin{document}




\lhead{Chapter 6: Eigenvalues}
\section*{Introduction to Eigenvalues and Eigenvectors}
\begin{itemize}
    \item \marginnote{1/28:}[-8.5mm]$Ax=b=\lambda x$
    \item $Ax=\lambda x$, $\lambda\in\mathbb{F}$, $x\in\mathbb{R}^n$
    \item $\lambda$ is an eigenvalue. $\lambda x$ is an eigenvector.
    \begin{equation*}
        A=
        \begin{bmatrix}
            3 & 1\\
            1 & 3\\
        \end{bmatrix}
    \end{equation*}
    \item $
        x =
        \begin{bmatrix}
            1\\
            1\\
        \end{bmatrix}
    $ is an eigenvector of $A$ with corresponding eigenvalue of $4$.
    \item $
        \begin{bmatrix}
            3 & 1\\
            1 & 3\\
        \end{bmatrix}
        \begin{bmatrix}
            1\\
            1\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            4\\
            4\\
        \end{bmatrix}
        = 4
        \begin{bmatrix}
            1\\
            1\\
        \end{bmatrix}
    $
    \begin{center}
        \begin{tikzpicture}
            \draw (-2,0) -- (2,0);
            \draw (0,-2) -- (0,2);
            \draw [thick,->] (0,0) -- node[right]{$x$} (0.5,0.5);
            \draw [thick,dashed,->] (0,0) -- node[right]{$Ax$} (2,2);
        \end{tikzpicture}
    \end{center}
    \begin{align*}
        Ax &= \lambda x\\
        Ax-\lambda x &= 0\\
        Ax-\lambda Ix &= 0\\
        (A-\lambda I)x &= 0
    \end{align*}
    \item $(A-\lambda I)x=0 \Rightarrow x\in N(A-\lambda I)^[$\footnote{To have a null space, $A-\lambda I$ has free columns.}$^] \Rightarrow |A-\lambda I|=0$
    \item $
        \begin{bmatrix}
            3 & 1\\
            1 & 3\\
        \end{bmatrix}
        -
        \begin{bmatrix}
            \lambda & 0\\
            0 & \lambda\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            3-\lambda & 1\\
            1 & 3-\lambda\\
        \end{bmatrix}
    $
    \item $
        \begin{vmatrix}
            3-\lambda & 1\\
            1 & 3-\lambda\\
        \end{vmatrix}
        = 0
    $
    \begin{align*}
        0 &= (3-\lambda)^2-1^2\\
        &= 3^2-6\lambda+\lambda^2-1\\
        &= \lambda^2-6\lambda+8\\
        &= (\lambda-4)(\lambda-2)
    \end{align*}
    \item $\lambda=4,2$.
    \item $\lambda^2-6\lambda+8$ is the \textbf{characteristic polynomial} of $A$.
    \item $
        A-2I =
        \begin{bmatrix}
            -1 & 1\\
            1 & -1\\
        \end{bmatrix}
        ,\ 
        x =
        \begin{bmatrix}
            1\\
            -1\\
        \end{bmatrix}
        \in N(A-2I)
    $.
    \item $
        A-4I =
        \begin{bmatrix}
            -1 & 1\\
            1 & -1\\
        \end{bmatrix}
        ,\ 
        x =
        \begin{bmatrix}
            1\\
            1\\
        \end{bmatrix}
        \in N(A-4I)
    $.
    \item "Eigenspace" is not $\mathbb{R}^2$, but two lines in $\mathbb{R}^2$, specifically $y=\pm x$.
    \begin{itemize}
        \item $y=\pm x$ comes from $c_1\begin{bmatrix}1\\1\end{bmatrix}$ and $c_2\begin{bmatrix}1\\-1\end{bmatrix}$.
    \end{itemize}

    %%%%%%%%%%%%%%%%%%%%%%

    \marginnote{1/29:}\begin{equation*}
        A =
        \begin{bmatrix}
            2 & -2 & 3\\
            0 & 3 & -2\\
            0 & -1 & 2\\
        \end{bmatrix}
    \end{equation*}
    \begin{align*}
        P(\lambda) &= |A-\lambda I|\\
        &=
        \begin{vmatrix}
            2-\lambda & -2 & 3\\
            0 & 3-\lambda & -2\\
            0 & -1 & 2-\lambda\\
        \end{vmatrix}\\
        &= -1
        \begin{vmatrix}
            2-\lambda & 3\\
            0 & -2\\
        \end{vmatrix}
        (-1)^{3+2} + (2-\lambda)
        \begin{vmatrix}
            2-\lambda & -2\\
            0 & 3-\lambda\\
        \end{vmatrix}
        (-1)^{3+3}\\
        &= ((2-\lambda)(-2))+(2-\lambda)((2-\lambda)(3-\lambda))\\
        &= -4+2\lambda+(2-\lambda)^2(3-\lambda)\\
        &= -4+2\lambda+(4-4\lambda+\lambda^2)(3-\lambda)\\
        &= -4+2\lambda+12-4\lambda-12\lambda+4\lambda^2+3\lambda^2-\lambda^3\\
        &= -\lambda^3+7\lambda^2-14\lambda+8\\
        &= -(\lambda-1)(\lambda-2)(\lambda-4)
    \end{align*}
    \begin{align*}
        A-I &=
        \begin{bmatrix}
            1 & -2 & 3\\
            0 & 2 & -2\\
            0 & -1 & 1\\
        \end{bmatrix}&
        A-2I &=
        \begin{bmatrix}
            0 & -2 & 3\\
            0 & 1 & -2\\
            0 & -1 & 0\\
        \end{bmatrix}&
        A-4I &=
        \begin{bmatrix}
            -2 & -2 & 3\\
            0 & -1 & -2\\
            0 & -1 & -2\\
        \end{bmatrix}&
    \end{align*}
    \item $P(\lambda)$ is positive when $n\in 2\mathbb{N}$, negative otherwise.
    \begin{itemize}
        \item Signs flip term to term (think about binomial expansion).
    \end{itemize}
    \item Coefficient of the $n-1$ degree term is the sum of the diagonal entries.
    \item Coefficient of the $0^\text{th}$ degree term is $|A|$.
    \begin{itemize}
        \item $P_\lambda(0) = |A-0\cdot I| = |A|$.
    \end{itemize}
    \item Product of the eigenvalues is $|A|$.
    \begin{itemize}
        \item Think about expanding the factorization of $P(\lambda)$.
    \end{itemize}
    \item Eigenvalues of $U$ are the diagonal values.
    \begin{itemize}
        \item $\lambda_1\lambda_2\cdots\lambda_n=|A|$, which is the product of the diagonal entries.
        \item $\lambda_1+\cdots+\lambda_n=\text{trace}(A)$, which is the sum of the diagonal entries.
    \end{itemize}
    \item $Ax=\lambda x$
    \begin{itemize}
        \item $A^2x=AAx=A\lambda x=\lambda Ax=\lambda\lambda x=\lambda^2x$
    \end{itemize}
\end{itemize}



\section*{Similarity}
\begin{itemize}
    \item \marginnote{1/30:}$A\sim B$$^[$\footnote{$A$ "is similar to" $B$}$^]$ iff $\exists\ S:A=SBS^{-1},\ B=S^{-1}AS$.
    \begin{enumerate}
        \item If $A\sim B$, then $|A|=|B|$.
        \begin{align*}
            B &= S^{-1}AS\\
            |B| &= |S^{-1}AS|\\
            |B| &= |S^{-1}||A||S|\\
            |B| &= \frac{1}{|S|}|A||S|\\
            |B| &= |A|
        \end{align*}
        \item If $A\sim B$, then they share the same characteristic polynomial.
        \begin{align*}
            B &= S^{-1}AS\\
            |B-\lambda I| &= |S^{-1}AS-\lambda I|\\
            &= |S^{-1}AS-\lambda S^{-1}IS|\\
            &= |S^{-1}S(A-\lambda I)|\\
            &= |I(A-\lambda I)|\\
            |B-\lambda I| &= |A-\lambda I|
        \end{align*}
        \begin{itemize}
            \item If they have the same characteristic polynomial, $\therefore$ $A$ and $B$ have the same eigenvalues.
        \end{itemize}
    \end{enumerate}
    \item What is the best possible $B$ if $A\sim B$?
    \begin{itemize}
        \item Sparse.
        \item Diagonal.
        \item $
            A=[\text{ugly}]\quad\rightarrow\quad
            B=\begin{bmatrix}
                \lambda_1 &  & 0\\
                 & \ddots & \\
                0 &  & \lambda_n\\
            \end{bmatrix}
            =\Lambda
        $
    \end{itemize}
    \item \textbf{Diagonalization}:
    \begin{align*}
        A &= S\Lambda S^{-1}\\
        AS &= S\Lambda\\
        \Lambda &= S^{-1}AS
    \end{align*}
    \item $A=S\Lambda S^{-1}$
    \begin{itemize}
        \item $A^2 = AA = S\Lambda S^{-1}S\Lambda S^{-1} = S\Lambda\Lambda S^{-1} = S\Lambda^2 S^{-1}$
        \item $A^k = S\Lambda^k S^{-1}$
        \item $
            A^k = S
            \begin{bmatrix}
                {\lambda_1}^k &  & 0\\
                 & \ddots & \\
                0 &  & {\lambda_n}^k\\
            \end{bmatrix}
            S^{-1}
        $
    \end{itemize}
    \item Diagonalize the following matrix $A$.
    \begin{equation*}
        A =
        \begin{bmatrix}
            -1 & 0 & 1\\
            3 & 0 & -3\\
            1 & 0 & -1\\
        \end{bmatrix}
    \end{equation*}
    \begin{itemize}
        \item Find the characteristic polynomial.
        \begin{align*}
            |A-\lambda I| &=
            \begin{vmatrix}
                -1-\lambda & 0 & 1\\
                3 & 0-\lambda & -3\\
                1 & 0 & -1-\lambda\\
            \end{vmatrix}\\
            &= (-1-\lambda)((-\lambda)(-1-\lambda))+(-1)(-\lambda)\\
            &= -\lambda(-1-\lambda)^2+\lambda\\
            &= -\lambda(1+2\lambda+\lambda^2)+\lambda\\
            &= -\lambda^3-2\lambda^2\\
            &= -\lambda^2(\lambda+2)
        \end{align*}
        \item Find the eigenvalues: $\lambda_1=\lambda_2=0$, $\lambda_3=-2$
        \item \textbf{Algebraic multiplicity} of $\lambda_1,\lambda_2$ is 2.
        \item A.M. of $\lambda_3$ is 1.
        \item $
            A-0I =
            \begin{bmatrix}
                -1 & 0 & 1\\
                3 & 0 & -3\\
                1 & 0 & -1\\
            \end{bmatrix}
        $
        \item $\text{rank}(A-0I)=1 \Rightarrow \dim(N(A-0I))=2$
        \item The 2 directly above is the \textbf{geometric multiplicity}.
        \item $A$ is diagonalizable iff A.M. of $\lambda_i=\text{G.M.}$
        
        %%%%%%%%%%%%%%%%%%%%%%%%%
        
        \item \marginnote{1/31:}Eigenvectors are $
            x_1=
            \begin{bmatrix}
                1\\
                0\\
                1\\
            \end{bmatrix}
        $ and $
            x_2=
            \begin{bmatrix}
                0\\
                1\\
                0\\
            \end{bmatrix}
        $.
        \item $
        A+2I =
        \begin{bmatrix}
            1 & 0 & 1\\
            3 & 2 & -3\\
            1 & 0 & 1\\
        \end{bmatrix}
    $
        \item Eigenvector is $
            x_3=
            \begin{bmatrix}
                1\\
                -3\\
                -1\\
            \end{bmatrix}
        $.
        \item Use an $S$ matrix of eigenvectors.
        \item $
            A = S\Lambda S^{-1} = \frac{1}{2}
            \begin{bmatrix}
                0 & 1 & 1\\
                1 & 0 & -3\\
                0 & 1 & -1\\
            \end{bmatrix}
            \begin{bmatrix}
                0 &  & \\
                 & 0 & \\
                 &  & -2\\
            \end{bmatrix}
            \begin{bmatrix}
                3 & 2 & -3\\
                1 & 0 & 1\\
                1 & 0 & -1\\
            \end{bmatrix}
        $
        \item Note that $
            A^{9752} = \frac{1}{2}
            \begin{bmatrix}
                0 & 1 & 1\\
                1 & 0 & -3\\
                0 & 1 & -1\\
            \end{bmatrix}
            \begin{bmatrix}
                0 &  & \\
                 & 0 & \\
                 &  & (-2)^{9752}\\
            \end{bmatrix}
            \begin{bmatrix}
                3 & 2 & -3\\
                1 & 0 & 1\\
                1 & 0 & -1\\
            \end{bmatrix}
        $
    \end{itemize}
    \item \textbf{Algebraic multiplicity}: The number of repeated roots to a polynomial. For all of the roots, it adds up to $n$ ($n$-square matrix). \emph{Also known as} \textbf{A.M.}
    \item \textbf{Geometric multiplicity}: The number of eigenvectors produced from each root. For all of the roots, it may not add up to $n$ ($n$-square matrix). $\dim(N(A-\lambda I))$. \emph{Also known as} \textbf{G.M.}
    \item A nondiagonalizable example:
    \begin{equation*}
        A =
        \begin{bmatrix}
            1 & 1 & 0\\
            0 & 1 & 1\\
            0 & 0 & 4\\
        \end{bmatrix}
    \end{equation*}
    \begin{itemize}
        \item $\lambda_1 = \lambda_2 = 1$ and $\lambda_3 = 4$.
        \item $\lambda_1$ and $\lambda_2$ have $\text{A.M.}={\color{red}2}$.
        \item $\lambda_3$ has $\text{A.M.}=1$.
        \item $
            A-I=
            \begin{bmatrix}
                0 & 1 & 0\\
                0 & 0 & 1\\
                0 & 0 & 3\\
            \end{bmatrix}
        $
        \item $\text{rank}(A-I)=2\Rightarrow\dim(N(A-I))=1\Rightarrow\text{G.M.}={\color{red}1}$.
        \item $
            x_1=
            \begin{bmatrix}
                1\\
                0\\
                0\\
            \end{bmatrix}
        $
        \item $
            A-4I=
            \begin{bmatrix}
                -3 & 1 & 0\\
                0 & -3 & 1\\
                0 & 0 & 0\\
            \end{bmatrix}
        $
        \item $
            x_2=
            \begin{bmatrix}
                1\\
                3\\
                9\\
            \end{bmatrix}
        $
        \item $S$ would be $3\times 2$ and, thus, not square, so $\nexists\ S^{-1}$$^[$\footnote{At a later date, we will look at an analogy of projections to diagonalization that finds the "best possible" diagonalization (which may not be perfectly diagonal).}$^]$.
    \end{itemize}
    \item \textbf{Canonical} (form): An accepted way of expressing something.
\end{itemize}



\section*{Markov Chains}
\marginnote{2/3:}
\begin{center}
    \begin{tikzpicture}
        \node (pgh) [circle,draw] {PGH}
            edge [out=100,in=130,loop,thick] node[above]{0.95} ()
        ;
        \node (cle) [circle,draw] at (5,0) {CLE}
            edge [out=80,in=50,loop,thick] node[above]{0.8} ()
        ;
        \draw [->,thick] (pgh) to[bend left=30] node[above]{0.05} (cle);
        \draw [->,thick] (cle) to[bend left=30] node[below]{0.2} (pgh);
    \end{tikzpicture}
\end{center}
\begin{itemize}
    \item $
        u_0 =
        \begin{bmatrix}
            500,000\\
            500,000\\
        \end{bmatrix}
    $
    \item $Au_0 = u_1$.
    \item $Au_1 = u_2$, $A(Au_0) = u_2$, $A^2u_0 = u_2$, $A^ku_0 = u_k$, $(S\Lambda S^{-1})^ku_0 = u_k$, $S\Lambda^kS^{-1}u_0 = u_k$.
    \begin{align*}
        A &=
        \begin{bmatrix}
            0.95 & 0.20\\
            0.05 & 0.80\\
        \end{bmatrix}&
        u_k &=
        \begin{bmatrix}
            \text{PGH}\\
            \text{CLE}\\
        \end{bmatrix}
    \end{align*}
    \item $A$ is a \textbf{Markov matrix}, where all columns and rows add to 1.
    \item $
        Au_0 =
        \begin{bmatrix}
            0.95 & 0.20\\
            0.05 & 0.80\\
        \end{bmatrix}
        \begin{bmatrix}
            500,000\\
            500,000\\
        \end{bmatrix}
        = u_1
    $
    \begin{align*}
        |A-\lambda I| &=
        \begin{vmatrix}
            0.95-\lambda & 0.20\\
            0.05 & 0.80-\lambda\\
        \end{vmatrix}\\
        &= (0.95-\lambda)(0.8-\lambda)-(0.2)(0.05)\\
        &= (\lambda-1)(\lambda-0.75)
    \end{align*}
    \item $\lambda_1 = 1,\ \lambda_2 = 0.75$.
    \item $
        A-I =
        \begin{bmatrix}
            -0.05 & 0.2\\
            0.05 & -0.2\\
        \end{bmatrix}
        \Rightarrow
        x =
        \begin{bmatrix}
            4\\
            1\\
        \end{bmatrix}
    $
    \item $
        A-0.75I =
        \begin{bmatrix}
            0.2 & 0.2\\
            0.05 & 0.05\\
        \end{bmatrix}
        \Rightarrow
        x =
        \begin{bmatrix}
            -1\\
            1\\
        \end{bmatrix}
    $
    \begin{align*}
        A^ku_0 &= \frac{1}{5}
        \begin{bmatrix}
            4 & -1\\
            1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            1 & 0\\
            0 & 0.75\\
        \end{bmatrix}^k
        \begin{bmatrix}
            1 & 1\\
            -1 & 4\\
        \end{bmatrix}
        \begin{bmatrix}
            500,000\\
            500,000\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            4 & -1\\
            1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            1 & 0\\
            0 & 0.75^k\\
        \end{bmatrix}
        \begin{bmatrix}
            200,000\\
            300,000\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            4\\
            1\\
        \end{bmatrix}
        (200,000) +
        \begin{bmatrix}
            -1\\
            1\\
        \end{bmatrix}
        (0.75)^k(300,000)
    \end{align*}
    \item $
        \begin{bmatrix}
            800,000\\
            200,000\\
        \end{bmatrix}
    $ is the steady-state vector.
    \item $
        \begin{bmatrix}
            -(0.75)^k(300,000)\\
            (0.75)^k(300,000)\\
        \end{bmatrix}
    $ is the dynamically changing vector.
    \item $
        \lim_{k\to\infty} A^ku_0 =
        \begin{bmatrix}
            800,000\\
            200,000\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            \text{PGH}\\
            \text{CLE}\\
        \end{bmatrix}
    $
\end{itemize}


\subsection*{Explicit Formula for the Fibonacci Sequence}
\begin{itemize}
    \item \marginnote{2/4:}1, 1, 2, 3, 5, 8, \dots
    \item Recursively defined formula: $F_n$$^[$\footnote{The $n$-th Fibonacci number.}$^]$$=F_{n-1}+F_{n-2}$.
    \begin{align*}
        F_n &= F_{n-1}+F_{n-2}\\
        F_{n-1} &= F_{n-1}\\
        \begin{bmatrix}
            F_n\\
            F_{n-1}\\
        \end{bmatrix}
        &=
        \begin{bmatrix}
            1 & 1\\
            1 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
            F_{n-1}\\
            F_{n-2}\\
        \end{bmatrix}
    \end{align*}
    \item $u_n = A^nu_0 = S\Lambda^nS^{-1}u_0$.
    \begin{align*}
        0 &= |A-\lambda I|\\
        &=
        \begin{vmatrix}
            1-\lambda & 1\\
            1 & -\lambda\\
        \end{vmatrix}\\
        &= -\lambda(1-\lambda)-1\\
        &= \lambda^2-\lambda-1
    \end{align*}
    \item $\lambda = \frac{1\pm\sqrt{5}}{2}$$^[$\footnote{This is the Golden ratio!}$^]$.
    \item $\lambda_1 = \frac{1+\sqrt{5}}{2}$.
    \begin{align*}
        N(A-\lambda_1I) &= N\left(
        \begin{bmatrix}
            1-\frac{1+\sqrt{5}}{2} & 1\\
            1 & -\frac{1+\sqrt{5}}{2}\\
        \end{bmatrix}
        \right)\\
        &= N\left(
        \begin{bmatrix}
            \frac{1-\sqrt{5}}{2} & 1\\
            1 & \frac{-1-\sqrt{5}}{2}\\
        \end{bmatrix}
        \right)\\
    \end{align*}
    \item $
        \begin{bmatrix}
            \frac{1-\sqrt{5}}{2} & 1\\
            1 & \frac{-1-\sqrt{5}}{2}\\
        \end{bmatrix}
        \begin{bmatrix}
            x_1\\
            x_2\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            0\\
            0\\
        \end{bmatrix}
    $
    \item Let $x_2=1$.
    \begin{align*}
        \frac{1-\sqrt{5}}{2}x_1+1 &= 0\\
        \frac{1-\sqrt{5}}{2}x_1 &= -\frac{2}{2}\\
        x_1 &= \frac{-2}{1-\sqrt{5}}\times \frac{1+\sqrt{5}}{1+\sqrt{5}}\\
        &= \frac{-2-2\sqrt{5}}{-4}\\
        &= \frac{1+\sqrt{5}}{2}
    \end{align*}
    \item $
        s_1 =
        \begin{bmatrix}
            \frac{1+\sqrt{5}}{2}\\
            1\\
        \end{bmatrix}
    $, $
        s_2 =
        \begin{bmatrix}
            \frac{1-\sqrt{5}}{2}\\
            1\\
        \end{bmatrix}
    $.
    \item $
        \begin{bmatrix}
            1 & 1\\
            1 & 0\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            \frac{1+\sqrt{5}}{2} & \frac{1-\sqrt{5}}{2}\\
            1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            \frac{1+\sqrt{5}}{2} & 0\\
            0 & \frac{1-\sqrt{5}}{2}\\
        \end{bmatrix}
        S^{-1}
    $
    \item $
        S^{-1}
        = \frac{1}{|S|}C_S^\T
        = \frac{1}{\sqrt{5}}
        \begin{bmatrix}
            1 & \frac{-1+\sqrt{5}}{2}\\
            -1 & \frac{1+\sqrt{5}}{2}\\
        \end{bmatrix}
    $
    \item $u_k = A^ku_0 = S\Lambda^kS^{-1}u_0$.
    \begin{align*}
        S^{-1}u_0 &= \frac{1}{\sqrt{5}}
        \begin{bmatrix}
            1 & \frac{-1+\sqrt{5}}{2}\\
            -1 & \frac{1+\sqrt{5}}{2}\\
        \end{bmatrix}
        \begin{bmatrix}
            1\\
            1\\
        \end{bmatrix}\\
        &= \frac{1}{\sqrt{5}}
        \begin{bmatrix}
            \frac{1+\sqrt{5}}{2}\\
            \frac{-1+\sqrt{5}}{2}\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            \frac{1+\sqrt{5}}{2\sqrt{5}}\\
            \frac{-1+\sqrt{5}}{2\sqrt{5}}\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            \frac{5+\sqrt{5}}{10}\\
            \frac{5-\sqrt{5}}{10}\\
        \end{bmatrix}
    \end{align*}
    \item $
        u_k =
        \begin{bmatrix}
            \frac{1+\sqrt{5}}{2}\\
            1\\
        \end{bmatrix}
        \left( \frac{1+\sqrt{5}}{2} \right)^k\left( \frac{5+\sqrt{5}}{10} \right)+
        \begin{bmatrix}
            \frac{1-\sqrt{5}}{2}\\
            1\\
        \end{bmatrix}
        \left( \frac{1-\sqrt{5}}{2} \right)^k\left( \frac{5-\sqrt{5}}{10} \right)
    $
\end{itemize}



\section*{Systems of First-Order Ordinary Differential Equations}
\begin{itemize}
    \item \marginnote{2/11:}Let $f(x)=y$ and $a,c,K\in\mathbb{F}$.
    \begin{align*}
        \dd[y]{x} &= ay\\
        \frac{1}{y}\dd[y]{x} &= a\\
        \frac{1}{y}\dd[y]{x}\, \dx &= a\, \dx\\
        \frac{1}{y}\, \dy &= a\, \dx\\
        \int \frac{1}{y}\, \dy &= \int a\, \dx\\
        \ln y &= ax+c\\
        y &= \e^{ax+c}\\
        &= \e^{ax}\text{e}^c\\
        &= K\e^{ax}
    \end{align*}
    \item Let $\dd[y]{x}=y'$.
    \begin{itemize}
        \item $y_1' = a_{11}y_1+a_{12}y_2+\cdots+a_{1n}y_n$.
        \item $y_2' = a_{21}y_1+a_{22}y_2+\cdots+a_{2n}y_n$.
        \item $\vdots$
        \item $y_n' = a_{n1}y_1+a_{n2}y_2+\cdots+a_{nn}y_n$.
    \end{itemize}
    \item This is a \textbf{square system} of equations.
    \item Rewrite as $y' = Ay$.
    \begin{equation*}
        \begin{bmatrix}
            y_1'\\
            y_2'\\
            \vdots\\
            y_n'\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            a_{11} & a_{12} & \cdots & a_{1n}\\
            a_{21} & a_{22} & \cdots & a_{2n}\\
            \vdots &        & \ddots &       \\
            a_{n1} & a_{n2} & \cdots & a_{nn}\\
        \end{bmatrix}
        \begin{bmatrix}
            y_1\\
            y_2\\
            \vdots\\
            y_n\\
        \end{bmatrix}
    \end{equation*}
    \item Solve the following system of differential equations.
    \begin{align*}
        y_1' &= 3y_1\\
        y_2' &= -2y_2\\
        y_3' &= 5y_3
    \end{align*}
    \begin{equation*}
        \begin{bmatrix}
            y_1'\\
            y_2'\\
            y_3'\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            3 & 0 & 0\\
            0 & -2 & 0\\
            0 & 0 & 5\\
        \end{bmatrix}
        \begin{bmatrix}
            y_1\\
            y_2\\
            y_3\\
        \end{bmatrix}
    \end{equation*}
    \begin{itemize}
        \item General Solution:
    \end{itemize}
    \begin{align*}
        y_1 &= k_1\e^{3x}\\
        y_2 &= k_2\e^{-2x}\\
        y_3 &= k_3\e^{5x}
    \end{align*}
    \begin{itemize}
        \item Particular Solution (where $y_1(0)=2$, $y_2(0)=-1$, and $y_3(0)=7$ are the initial conditions):
    \end{itemize}
    \begin{align*}
        y_1 &= 2\e^{3x}\\
        y_2 &= -\e^{-2x}\\
        y_3 &= 7\e^{5x}
    \end{align*}
    \item Consider a different system. Remember throughout that we are solving for $y$.
    \begin{align*}
        y_1' &= y_1+y_2\\
        y_2' &= 4y_1-2y_2
    \end{align*}
    \begin{itemize}
        \item The previous system was so easy to solve because the matrix was diagonal. This one (as follows) will not be. Therefore, we should diagonalize it.
    \end{itemize}
    \begin{equation*}
        \begin{bmatrix}
            y_1'\\
            y_2'\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            1 & 1\\
            4 & -2\\
        \end{bmatrix}
        \begin{bmatrix}
            y_1\\
            y_2\\
        \end{bmatrix}
    \end{equation*}
    \begin{itemize}
        \item Start with $y'=Ay$.
        \item Substitute $y=Su$.
        \begin{itemize}
            \item Note that $y=Su\Rightarrow y'=Su'$$^[$\footnote{Think about differentiating both sides: $y\rightarrow y'$ is obvious, $S$ will be unchanged because it's just coefficients, and the functions of $u$ will be differentiated.}$^]$.
            \item If we can find $u'$ in terms of a diagonal matrix and $u$, we can solve for $y$.
        \end{itemize}
        \begin{center}
            \begin{tikzpicture}
                \draw [red] (-2,0) -- (2,0) node[right]{
                    $
                        \begin{bmatrix}
                            1\\
                            0\\
                        \end{bmatrix}
                    $
                };
                \draw [red] (0,-2) -- (0,2) node[above]{
                    $
                        \begin{bmatrix}
                            0\\
                            1\\
                        \end{bmatrix}
                    $
                };

                \draw [blue] (-0.5,2) node[above left]{
                    $
                        S_2\
                        \begin{bmatrix}
                            -1\\
                            4\\
                        \end{bmatrix}
                    $
                } -- (0.5,-2);
                \draw [blue] (-2,-2) -- (2,2) node[right]{
                    $
                        S_1\
                        \begin{bmatrix}
                            1\\
                            1\\
                        \end{bmatrix}
                    $
                };

                \draw [thick] (-1,2) node[below left]{
                    $\color{red}y_1$
                } node[below=3mm]{
                    $\color{blue}u_1$
                } to[out=-45,in=180] (1.8,1.3);
                \draw [thick] plot[smooth,tension=1.2] coordinates{
                    (-1,-1) (-0.5,-0.3) (0.2,-0.6) (1,0.4)
                };
                \node at (-0.8,-1.2) {
                    $\color{red}y_2$
                };
                \node at (-0.5,-0.9) {
                    $\color{blue}u_2$
                };
            \end{tikzpicture}
        \end{center}
        \item We seek to find a new basis $S$ such that the matrix scaling $u$ will be diagonal.
    \end{itemize}
    \begin{align*}
        Su' &= Ay\\
        Su' &= ASu\\
        u' &= S^{-1}ASu\\
        u' &= \Lambda u
    \end{align*}
    \begin{itemize}
        \item The last substitution above is legal because if $A=S\Lambda S^{-1}$, then $\Lambda=S^{-1}AS$.
    \end{itemize}
    \begin{align*}
        0 &=
        \begin{vmatrix}
            1-\lambda & 1\\
            4 & -2-\lambda\\
        \end{vmatrix}\\
        &= (1-\lambda)(-2-\lambda)-4\\
        &= -2-\lambda+2\lambda+\lambda^2-4\\
        &= \lambda^2+\lambda-6\\
        &= (\lambda-2)(\lambda+3)
    \end{align*}
    \begin{align*}
        \lambda_1 &= 2&
        \lambda_2 &= -3
    \end{align*}
    \begin{itemize}
        \item $
            A-2I=
            \begin{bmatrix}
                -1 & 1\\
                4 & -4\\
            \end{bmatrix}
            \begin{bmatrix}
                1\\
                1\\
            \end{bmatrix}
            =
            \begin{bmatrix}
                0\\
                0\\
            \end{bmatrix}
        $
        \item $
            A+3I=
            \begin{bmatrix}
                4 & 1\\
                4 & 1\\
            \end{bmatrix}
            \begin{bmatrix}
                -1\\
                4\\
            \end{bmatrix}
            =
            \begin{bmatrix}
                0\\
                0\\
            \end{bmatrix}
        $
    \end{itemize}
    \begin{align*}
        u' &= \Lambda u\\
        \begin{bmatrix}
            u_1'\\
            u_2'\\
        \end{bmatrix}
        &=
        \begin{bmatrix}
            2 & 0\\
            0 & -3\\
        \end{bmatrix}
        \begin{bmatrix}
            u_1\\
            u_2\\
        \end{bmatrix}
    \end{align*}
    \begin{align*}
        u_1 &= k_1\e^{2x}\\
        u_2 &= k_2\e^{-3x}
    \end{align*}
    \begin{align*}
        y &= Su\\
        \begin{bmatrix}
            y_1\\
            y_2\\
        \end{bmatrix}
        &=
        \begin{bmatrix}
            1 & -1\\
            1 & 4\\
        \end{bmatrix}
        \begin{bmatrix}
            k_1\e^{2x}\\
            k_2\e^{-3x}\\
        \end{bmatrix}
    \end{align*}
    \begin{align*}
        y_1 &= k_1\e^{2x}-k_2\e^{-3x}\\
        y_2 &= k_1\e^{2x}+4k_2\e^{-3x}
    \end{align*}

    %%%%%%%%%%%%%%%%%%%%%%

    \item \marginnote{2/12:}Initial conditions: $y_1(0)=1$ and $y_2(0)=6$.
    \begin{itemize}
        \item Use augmented matrices to solve a system of equations.
    \end{itemize}
    \begin{equation*}
        \begin{amatrix}{2}
            1 & -1 & 1\\
            1 & 4 & 6\\
        \end{amatrix}
        \rightarrow
        \begin{amatrix}{2}
            1 & 0 & 2\\
            0 & 1 & 1\\
        \end{amatrix}
    \end{equation*}
    \item Particular solution:
    \begin{align*}
        y_1 &= 2\e^{2x}-\e^{-3x}\\
        y_2 &= 2\e^{2x}+4\e^{-3x}
    \end{align*}
\end{itemize}


\subsection*{Matrix Exponentiation}
\begin{itemize}
    \item $\e^A$ is a matrix defined as the infinite sum of a power series.
    \item $f(t) = \e^t$.
\end{itemize}
\begin{tchart}{1.6}{Differential Equations}{Power Series}
    $f'(t)=f(t)$ & $f(t)=1+t+\frac{t^2}{2}+\frac{t^3}{3!}+\cdots$\\
    $f(0)=1$ & $\frac{\text{d}}{\text{d}t}(t)=1$, $\frac{\text{d}}{\text{d}t}\left( \frac{t^2}{2} \right)=t$, \dots\\
    & $f(t)=\sum_{n=0}^\infty \frac{t^n}{n!}$
\end{tchart}
\begin{itemize}
    \item $f(t)=\e^{at}$.
\end{itemize}
\begin{tchart}{1.5}{Differential Equations}{Power Series}
    $f'(t)=af(t)$ & $f(t)=\sum_{n=0}^\infty \frac{a^nt^n}{n!}$\\
    $f(0)=1$ &\\
\end{tchart}
\begin{itemize}
    \item $F(t)=\e^{At}$.
    \begin{itemize}
        \item A matrix-valued function.
        \item Ex. $
            F(\theta) =
            \begin{bmatrix}
                \cos(\theta) & -\sin(\theta)\\
                \sin(\theta) & \cos(\theta)\\
            \end{bmatrix}
        $
        \item $F(\theta)A$ rotates points (arrows) of $A$ by $\theta$.
    \end{itemize}
\end{itemize}
\begin{tchart}{1.5}{Differential Equations}{Power Series}
    $F'(t)=A\e^{At}$ & $F(t)=I+At+\frac{A^2t^2}{2!}+\frac{A^3t^3}{3!}+\cdots$\\
    $F(0)=I$ & $F(t)=\sum_{n=0}^\infty \frac{A^nt^n}{n!}$\\
\end{tchart}


\subsection*{Diagonalization of e\textsuperscript{\emph{At}}}
\begin{itemize}
    \item Find an alternate form for $\e^{At}$ by manipulating its power series definition:
    \begin{align*}
        \e^{At} &= \sum_{n=0}^\infty \frac{A^nt^n}{n!}\\
        &= \sum_{n=0}^\infty \frac{S\Lambda^nS^{-1}t^n}{n!}\\
        &= \sum_{n=0}^\infty S\left( \frac{\Lambda^nt^n}{n!} \right)S^{-1}\\
        &= S\left( {\color{grx}\sum_{n=0}^\infty \frac{t^n}{n!}\Lambda^n} \right)S^{-1}\\
        &= S\left( \sum_{n=0}^\infty \frac{t^n}{n!}
        \begin{bmatrix}
            \lambda_1 &  & \\
             & \ddots & \\
             &  & \lambda_k\\
        \end{bmatrix}^n
        \right)S^{-1}\\
        &= S\left( \sum_{n=0}^\infty \frac{t^n}{n!}
        \begin{bmatrix}
            \lambda_1^n &  & \\
             & \ddots & \\
             &  & \lambda_k^n\\
        \end{bmatrix}
        \right)S^{-1}\\
        &= S\left( \sum_{n=0}^\infty
        \begin{bmatrix}
            \frac{t^n}{n!}\lambda_1^n &  & \\
             & \ddots & \\
             &  & \frac{t^n}{n!}\lambda_k^n\\
        \end{bmatrix}
        \right)S^{-1}\\
        &= S\left( \sum_{n=0}^\infty
        \begin{bmatrix}
            \frac{\lambda_1^nt^n}{n!} &  & \\
             & \ddots & \\
             &  & \frac{\lambda_k^nt^n}{n!}\\
        \end{bmatrix}
        \right)S^{-1}\\
        %
        %%%%%%%%%%%%%%%%%%%%%%
        %
        \marginnote{2/13:}&= S
        \begin{bmatrix}
            \sum_{n=0}^\infty \frac{\lambda_1^nt^n}{n!} &  & \\
             & \ddots & \\
             &  & \sum_{n=0}^\infty \frac{\lambda_k^nt^n}{n!}\\
        \end{bmatrix}
        S^{-1}\\
        &= S
        \begin{bmatrix}
            \e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1}\\
        &= S{\color{grx}\e^{\Lambda t}}S^{-1}\\
        &= F(t)
    \end{align*}
    \item Prove, using the above result, that $F'(t)$ can be defined in terms of $F(t)$:
    \begin{align*}
        F(t) &= \e^{At}\\
        &= S
        \begin{bmatrix}
            \e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1}
    \end{align*}
    \begin{align*}
        F'(t) &= \dd{t}\left( S
        \begin{bmatrix}
            \e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1} \right)\\
        &= S\dd{t}\left(
        \begin{bmatrix}
            \e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \e^{\lambda_kt}\\
        \end{bmatrix}
        \right)S^{-1}\\
        &= S
        \begin{bmatrix}
            \dd{t}\e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \dd{t}\e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1}\\
        &= S
        \begin{bmatrix}
            \lambda_1\e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \lambda_k\e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1}\\
        &= S
        \begin{bmatrix}
            \lambda_1 &  & \\
             & \ddots & \\
             &  & \lambda_k\\
        \end{bmatrix}
        \begin{bmatrix}
            \e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1}\\
        &= S
        \begin{bmatrix}
            \lambda_1 &  & \\
             & \ddots & \\
             &  & \lambda_k\\
        \end{bmatrix}
        I_k
        \begin{bmatrix}
            \e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1}\\
        &= {\color{red}S
        \begin{bmatrix}
            \lambda_1 &  & \\
             & \ddots & \\
             &  & \lambda_k\\
        \end{bmatrix}
        S^{-1}}{\color{blue}S
        \begin{bmatrix}
            \e^{\lambda_1t} &  & \\
             & \ddots & \\
             &  & \e^{\lambda_kt}\\
        \end{bmatrix}
        S^{-1}}\\
        &= {\color{red}A}{\color{blue}F(t)}\\
        &= A\e^{At}
    \end{align*}
    \item In other words, $y'(t)=Ay(t)$ and $y(0)=y_0$. The solution is $y=\e^{At}y_0$.
    \item Example:
    \begin{align*}
        y'_1 &= 5y_1+y_2& y_1(0) &= -3\\
        y'_2 &= -2y_1+2y_2& y_2(0) &= 8
    \end{align*}
    \begin{align*}
        y(t) &= \e^{At}y(0)\\
        &= S\e^{\Lambda t}S^{-1}y(0)
    \end{align*}
    \begin{align*}
        0 &= |A-\lambda I|\\
        &=
        \begin{vmatrix}
            5-\lambda & 1\\
            -2 & 2-\lambda\\
        \end{vmatrix}\\
        &= (\lambda-3)(\lambda-4)
    \end{align*}
    \begin{itemize}
        \item $
            A-3I =
            \begin{bmatrix}
                2 & 1\\
                -2 & -1\\
            \end{bmatrix}
        $
        \item $
            N(A-3I) = \left\{
            \begin{bmatrix}
                1\\
                -2\\
            \end{bmatrix}
            \right\}
        $
        \item $
            A-4I =
            \begin{bmatrix}
                1 & 1\\
                -2 & -2\\
            \end{bmatrix}
        $
        \item $
            N(A-4I) = \left\{
            \begin{bmatrix}
                -1\\
                1\\
            \end{bmatrix}
            \right\}
        $
    \end{itemize}
    \begin{align*}
        y(t) &= S\e^{\Lambda t}S^{-1}y(0)\\
        &=
        \begin{bmatrix}
            1 & -1\\
            -2 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            \e^{3t} & 0\\
            0 & \e^{4t}\\
        \end{bmatrix}
        \begin{bmatrix}
            -1 & -1\\
            -2 & -1\\
        \end{bmatrix}
        \begin{bmatrix}
            -3\\
            8\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            \e^{3t} & -\e^{4t}\\
            -2\e^{3t} & \e^{4t}\\
        \end{bmatrix}
        \begin{bmatrix}
            -1 & -1\\
            -2 & -1\\
        \end{bmatrix}
        \begin{bmatrix}
            -3\\
            8\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            -\e^{3t}+2\e^{4t} & -\e^{3t}+\e^{4t}\\
            2\e^{3t}-2\e^{4t} & 2\e^{3t}-\e^{4t}\\
        \end{bmatrix}
        \begin{bmatrix}
            -3\\
            8\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            3\e^{3t}-6\e^{4t}-8\e^{3t}+8\e^{4t}\\
            -6\e^{3t}+6\e^{4t}+16\e^{3t}-8\e^{4t}\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            -5\e^{3t}+2\e^{4t}\\
            10\e^{3t}-2\e^{4t}\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            y_1(t)\\
            y_2(t)\\
        \end{bmatrix}
    \end{align*}
\end{itemize}



\section*{Orthonormally Diagonalizable Matrices}
\begin{itemize}
    \item \marginnote{2/19:}$A=Q\Lambda Q^\T$.
    \begin{itemize}
        \item Eigenvectors are orthonormal.
    \end{itemize}
    \item $A^\T = \left( Q\Lambda Q^\T \right)^\T = Q^{\T\T}\Lambda^\T Q^\T = Q\Lambda Q^\T = A$.
    \item Prove that the symmetric matrices are exactly those that are orthonormally diagonalizable.
    \begin{itemize}
        \item Let $A = A^\T$.
        \begin{equation}\label{eqn:ortho1}
            Ax_1 = \lambda_1x_1
        \end{equation}
        \begin{equation}\label{eqn:ortho2}
            Ax_2 = \lambda_2x_2
        \end{equation}
        \item Multiply Equation \ref{eqn:ortho1} by $x_2^\T$ from Equation \ref{eqn:ortho2}.
        \begin{itemize}
            \item We have to relate the two equations.
            \item Later, we transpose, because we have to specifically target the properties of symmetric matrices.
        \end{itemize}
        \begin{align*}
            \lambda_1x_2^\T x_1 &= x_2^\T Ax_1\\
            &= (x_2^\T A)x_1\\
            &= \left( A^\T x_2 \right)^\T x_1\\
            &= \left( A x_2 \right)^\T x_1\\
            \lambda_1x_2^\T x_1 &= \lambda_2x_2^T x_1\\
            \lambda_1x_2^\T x_1-\lambda_2x_2^T x_1 &= 0\\
            x_2^\T x_1(\lambda_1-\lambda_2) &= 0
        \end{align*}
        \item The last line above implies that $x_2^\T x_1 = 0$ iff $\lambda_1\neq\lambda_2$.
    \end{itemize}
    \item The only matrices that we can guarantee will never have complex eigenvalues are symmetric matrices.
    \item On complex numbers/vectors:
    \begin{itemize}
        \item $z=a+bi$ and $\bar{z}=a-bi$, where $a,b\in\R$, $i=\sqrt{-1}$. Note that $\bar{z}$ is the \textbf{complex conjugate} of $z$.
        \item $z\bar{z} = a^2+b^2$.
        \item $
            x =
            \begin{bmatrix}
                a_1+b_1i\\
                \vdots\\
                a_n+b_ni\\
            \end{bmatrix}
        $ and $
            \bar{x} =
            \begin{bmatrix}
                a_1-b_1i\\
                \vdots\\
                a_n-b_ni\\
            \end{bmatrix}
        $.
    \end{itemize}
    \item Prove that when $A = A^\T$, $\lambda_n\in\R$.
    \begin{itemize}
        \item Let $A = A^\T$, $A\in\R^n$.
        \begin{equation}\label{eqn:ortho3}
            Ax = \lambda x
        \end{equation}
        \begin{equation*}
            \bar{A}\bar{x} = \bar{\lambda}\bar{x}
        \end{equation*}
        \item If $A\in\R^n$, then $A=\bar{A}$.
        \begin{align*}
            A\bar{x} &= \bar{\lambda}\bar{x}\\
            \left( A\bar{x} \right)^\T &= \left( \bar{\lambda}\bar{x} \right)^\T\\
            \bar{x}^\T A^\T &= \bar{\lambda}\bar{x}^\T\\
            \bar{x}^\T A &= \bar{\lambda}\bar{x}^\T\stepcounter{equation}\tag{\theequation}\label{eqn:ortho4}\\
        \end{align*}
        \item Multiply Equation \ref{eqn:ortho3} by $\bar{x}^\T$ from the left.
        \begin{itemize}
            \item ${\color{blue}\bar{x}^\T Ax} = {\color{red}\lambda\bar{x}^\T x}$.
        \end{itemize}
        \item Multiply Equation \ref{eqn:ortho4} by $x$ from the right.
        \begin{itemize}
            \item ${\color{blue}\bar{x}^\T Ax} = {\color{grx}\bar{\lambda}\bar{x}^\T x}$.
        \end{itemize}
        \item ${\color{red}\lambda\bar{x}^\T x} = {\color{grx}\bar{\lambda}\bar{x}^\T x} \Rightarrow \lambda = \bar{\lambda} \Rightarrow \lambda\in\R$.
    \end{itemize}
\end{itemize}



\subsection*{Spectral Decomposition}
\marginnote{2/20:}\begin{equation*}
    A =
    \begin{bmatrix}
        2 & 1 & 1\\
        1 & 2 & 1\\
        1 & 1 & 2\\
    \end{bmatrix}
\end{equation*}
\begin{itemize}
    \item $\lambda_1 = 4,\ \lambda_2=\lambda_3=1$.
    \item $
        x_1 =
        \begin{bmatrix}
            1\\
            1\\
            1\\
        \end{bmatrix}
    $, $
        x_2 =
        \begin{bmatrix}
            -1\\
            0\\
            1\\
        \end{bmatrix}
    $, $
        x_3 =
        \begin{bmatrix}
            -1\\
            1\\
            0\\
        \end{bmatrix}
    $.
    \begin{itemize}
        \item $x_1^\T x_2 = 0$, $x_1^\T x_3 = 0$, $x_2^\T x_3 = -1$.
    \end{itemize}
    \item Orthogonalize by Gram-Schmidt, inspection, put the vectors in a matrix and find the null space (the null vector will be orthogonal by the fundamental theorem).
    \item $
        x_3' =
        \begin{bmatrix}
            -1\\
            2\\
            -1\\
        \end{bmatrix}
    $.
    \begin{itemize}
        \item $x_3'$ is not scaled along its line by $A$, but it is scaled in the plane of $x_2$ and $x_3$ by $A$.
        \item $x_1^\T x_3' = 0$, $x_2^\T x_3' = 0$.
    \end{itemize}
    \item $
        q_1 = \frac{1}{\sqrt{3}}
        \begin{bmatrix}
            1\\
            1\\
            1\\
        \end{bmatrix}
    $, $
        q_2 = \frac{1}{\sqrt{2}}
        \begin{bmatrix}
            -1\\
            0\\
            1\\
        \end{bmatrix}
    $, $
        q_3 = \frac{1}{\sqrt{6}}
        \begin{bmatrix}
            -1\\
            2\\
            -1\\
        \end{bmatrix}
    $.
    \begin{align*}
        A &= Q\Lambda Q^\T\\
        &=
        \begin{bmatrix}
            | &  & |\\
            q_1 & \cdots & q_n\\
            | &  & |\\
        \end{bmatrix}
        \begin{bmatrix}
            \lambda_1 &  & \\
             & \ddots & \\
             &  & \lambda_n\\
        \end{bmatrix}
        \begin{bmatrix}
            \text{---} & q_1^\T & \text{---}\\
             & \vdots & \\
            \text{---} & q_n^\T & \text{---}\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            | &  & |\\
            q_1\lambda_1 & \cdots & q_n\lambda_n\\
            | &  & |\\
        \end{bmatrix}
        \begin{bmatrix}
            \text{---} & q_1^\T & \text{---}\\
             & \vdots & \\
            \text{---} & q_n^\T & \text{---}\\
        \end{bmatrix}\\
        &= \lambda_1q_1q_1^\T+\cdots+\lambda_nq_nq_n^\T
    \end{align*}
    \renewcommand{\arraystretch}{1.6}
    \item $
        q_1q_1^\T =
        \begin{bmatrix}
            \frac{1}{\sqrt{3}}\\
            \frac{1}{\sqrt{3}}\\
            \frac{1}{\sqrt{3}}\\
        \end{bmatrix}
        \begin{bmatrix}
            \frac{1}{\sqrt{3}} & \frac{1}{\sqrt{3}} & \frac{1}{\sqrt{3}}\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
        \end{bmatrix}
    $
    \item $
        q_2q_2^\T =
        \begin{bmatrix}
            -\frac{1}{\sqrt{2}}\\
            0\\
            \frac{1}{\sqrt{2}}\\
        \end{bmatrix}
        \begin{bmatrix}
            -\frac{1}{\sqrt{2}} & 0 & \frac{1}{\sqrt{2}}\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            \frac{1}{2} & 0 & -\frac{1}{2}\\
            0 & 0 & 0\\
            -\frac{1}{2} & 0 & \frac{1}{2}\\
        \end{bmatrix}
    $
    \item $
        q_3q_3^\T =
        \begin{bmatrix}
            -\frac{1}{\sqrt{6}}\\
            \frac{2}{\sqrt{6}}\\
            -\frac{1}{\sqrt{6}}\\
        \end{bmatrix}
        \begin{bmatrix}
            -\frac{1}{\sqrt{6}} & \frac{2}{\sqrt{6}} & -\frac{1}{\sqrt{6}}\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            \frac{1}{6} & -\frac{1}{3} & \frac{1}{6}\\
            -\frac{1}{3} & \frac{2}{3} & -\frac{1}{3}\\
            \frac{1}{6} & -\frac{1}{3} & \frac{1}{6}\\
        \end{bmatrix}
    $
    \item $
        A = 4
        \begin{bmatrix}
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
        \end{bmatrix}
        +
        \begin{bmatrix}
            \frac{1}{2} & 0 & -\frac{1}{2}\\
            0 & 0 & 0\\
            -\frac{1}{2} & 0 & \frac{1}{2}\\
        \end{bmatrix}
        +
        \begin{bmatrix}
            \frac{1}{6} & -\frac{1}{3} & \frac{1}{6}\\
            -\frac{1}{3} & \frac{2}{3} & -\frac{1}{3}\\
            \frac{1}{6} & -\frac{1}{3} & \frac{1}{6}\\
        \end{bmatrix}
    $
    \item $
        A = 4
        \begin{bmatrix}
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
            \frac{1}{3} & \frac{1}{3} & \frac{1}{3}\\
        \end{bmatrix}
        +
        \begin{bmatrix}
            \frac{2}{3} & -\frac{1}{3} & -\frac{1}{3}\\
            -\frac{1}{3} & \frac{2}{3} & -\frac{1}{3}\\
            -\frac{1}{3} & -\frac{1}{3} & \frac{2}{3}\\
        \end{bmatrix}
    $ is the spectral decomposition of $A$.
    \renewcommand{\arraystretch}{1}
\end{itemize}



\includepdf[pages=-]{QuadricSurfacesSketching.pdf}



\section*{Quadric Forms / Positive Definite Matrices}
\begin{itemize}
    \item \marginnote{2/24:}Motivation: Find bases for conic sections that eliminate rotation terms.
    \renewcommand{\arraystretch}{1.6}
    \item Let $
        x =
        \begin{bmatrix}
            x\\
            y\\
            z\\
        \end{bmatrix}
    $, $
        A =
        \begin{bmatrix}
            a & \frac{d}{2} & \frac{e}{2}\\
            \frac{d}{2} & b & \frac{f}{2}\\
            \frac{e}{2} & \frac{f}{2} & c\\
        \end{bmatrix}
    $.
    \begin{align*}
        x^\T Ax &=
        \renewcommand{\arraystretch}{1}
        \begin{bmatrix}
            x & y & z\\
        \end{bmatrix}
        \renewcommand{\arraystretch}{1.6}
        \begin{bmatrix}
            a & \frac{d}{2} & \frac{e}{2}\\
            \frac{d}{2} & b & \frac{f}{2}\\
            \frac{e}{2} & \frac{f}{2} & c\\
        \end{bmatrix}
        \begin{bmatrix}
            x\\
            y\\
            z\\
        \end{bmatrix}\\
        &=
        \renewcommand{\arraystretch}{1}
        \begin{bmatrix}
            ax+\frac{d}{2}y+\frac{e}{2}z & \frac{d}{2}x+by+\frac{f}{2}z & \frac{e}{2}x+\frac{f}{2}y+zc
        \end{bmatrix}
        \begin{bmatrix}
            x\\
            y\\
            z\\
        \end{bmatrix}\\
        &= x\left( ax+\frac{d}{2}y+\frac{e}{2}z \right)+y\left( \frac{d}{2}x+by+\frac{f}{2}z \right)+z\left( \frac{e}{2}x+\frac{f}{2}y+zc \right)\\
        &= ax^2+\frac{d}{2}xy+\frac{e}{2}xz+\frac{d}{2}xy+by^2+\frac{f}{2}yz+\frac{e}{2}xz+\frac{f}{2}yz+cz^2\\
        &= ax^2+by^2+cz^2+dxy+exz+fyz
    \end{align*}
    \item Example:
    \begin{equation*}
        f(x,y) = z = 5x^2+4xy+2y^2
    \end{equation*}
    \begin{itemize}
        \item An elliptic paraboloid (but not necessary to know this).
        \begin{align*}
            x^\T Ax &=
            \renewcommand{\arraystretch}{1}
            \begin{bmatrix}
                x & y\\
            \end{bmatrix}
            \renewcommand{\arraystretch}{1.6}
            \begin{bmatrix}
                5 & \frac{4}{2}\\
                \frac{4}{2} & 2\\
            \end{bmatrix}
            \begin{bmatrix}
                x\\
                y\\
            \end{bmatrix}\\
            &=
            \renewcommand{\arraystretch}{1}
            \begin{bmatrix}
                x & y\\
            \end{bmatrix}
            \begin{bmatrix}
                5 & 2\\
                2 & 2\\
            \end{bmatrix}
            \begin{bmatrix}
                x\\
                y\\
            \end{bmatrix}
        \end{align*}
        \item Let $x=Qy\Rightarrow y=Q^\T x$.
        \item If $A=A^\T$, then $A=Q\Lambda Q^\T\Rightarrow{\color{red}\Lambda}={\color{blue}Q^\T AQ}$.
        \begin{align*}
            x^\T Ax &= (Qy)^\T A(Qy)\\
            &= y^\T {\color{blue}Q^\T AQ}y\\
            &= y^\T{\color{red}\Lambda} y
        \end{align*}
        \renewcommand{\arraystretch}{1}
        \item Diagonalize $A$.
        \begin{align*}
            0 &= |A-\lambda I|\\
            &=
            \begin{vmatrix}
                5-\lambda & 2\\
                2 & 2-\lambda\\
            \end{vmatrix}\\
            &= (5-\lambda)(2-\lambda)-4\\
            &= \lambda^2-7\lambda+6
        \end{align*}
        \begin{align*}
            \lambda_1 &= 1 & \lambda_2 &= 6
        \end{align*}
        \item $
            N(A-I) = N\left( 
                \begin{bmatrix}
                    4 & 2\\
                    2 & 1\\
                \end{bmatrix}
            \right)
            =\left\{ 
                \begin{bmatrix}
                    1\\
                    -2\\
                \end{bmatrix}
            \right\}
        $
        \item $
            N(A-6I) = N\left( 
                \begin{bmatrix}
                    -1 & 2\\
                    2 & -4\\
                \end{bmatrix}
            \right)
            =\left\{ 
                \begin{bmatrix}
                    2\\
                    1\\
                \end{bmatrix}
            \right\}
        $
        \renewcommand{\arraystretch}{1.6}
        \item $
            q_1 =
            \begin{bmatrix}
                \frac{1}{\sqrt{5}}\\
                -\frac{2}{\sqrt{5}}\\
            \end{bmatrix}
        $
        \item $
            q_2 =
            \begin{bmatrix}
                \frac{2}{\sqrt{5}}\\
                \frac{1}{\sqrt{5}}\\
            \end{bmatrix}
        $
        \renewcommand{\arraystretch}{1}
        \item On standard basis: $f(x,y)=5x^2+4xy+4y^2$.
        \item On basis $Q$: $f(x,y)=x^2+6y^2$.
        \item We're rotating the $x$ and $y$ axes by the same angle and keeping them orthogonal:
        \begin{center}
            \begin{tikzpicture}
                \draw [blue] (-2,0) -- (2,0)node[right]{
                    $
                        \begin{bmatrix}
                            1\\
                            0\\
                        \end{bmatrix}
                    $
                };
                \draw [blue] (0,-2) -- (0,2)node[above]{
                    $
                        \begin{bmatrix}
                            0\\
                            1\\
                        \end{bmatrix}
                    $
                };

                \draw [red] (-2,-1) -- (2,1)node[right]{
                    $
                        \begin{bmatrix}
                            2\\
                            1\\
                        \end{bmatrix}
                    $
                };
                \draw [red] (-1,2) -- (1,-2)node[right]{
                    $
                        \begin{bmatrix}
                            1\\
                            -2\\
                        \end{bmatrix}
                    $
                };
            \end{tikzpicture}
        \end{center}
    \end{itemize}
    \item How are they equivalent?
    \begin{itemize}
        \item Let $
            x=
            \begin{bmatrix}
                1\\
                3\\
            \end{bmatrix}
        $
        \item $x^\T Ax = 5(1)^2+4(1)(3)+2(3^2) = 35$.
        \item $
            y = Q^\T x =
            \begin{bmatrix}
                \frac{1}{\sqrt{5}} & -\frac{2}{\sqrt{5}}\\
                \frac{2}{\sqrt{5}} & \frac{1}{\sqrt{5}}\\
            \end{bmatrix}
            \begin{bmatrix}
                1\\
                3\\
            \end{bmatrix}
            =
            \begin{bmatrix}
                -\frac{5}{\sqrt{5}}\\
                \frac{5}{\sqrt{5}}\\
            \end{bmatrix}
            =
            \begin{bmatrix}
                -\sqrt{5}\\
                \sqrt{5}\\
            \end{bmatrix}
        $
        \item $y^\T \Lambda y = \left( -\sqrt{5} \right)^2+6\left( \sqrt{5} \right)^2 = 35$.
    \end{itemize}
\end{itemize}


\subsection*{Sketching a Rotated Conic}
\begin{itemize}
    \item \marginnote{2/25:}Principal Axes Theorem: $x^\T Ax \rightarrow y^\T\Lambda y$.
    \item Consider $13x^2-10xy+13y^2-72=0$.
    \begin{itemize}
        \item We want to reexpress this using the Principal Axes Theorem to deal with the rotation term.
        \item $
            x^\T Ax = 72 =
            \begin{bmatrix}
                x & y\\
            \end{bmatrix}
            \begin{bmatrix}
                13 & -5\\
                -5 & 13\\
            \end{bmatrix}
            \begin{bmatrix}
                x\\
                y\\
            \end{bmatrix}
        $
        \item $0 = |A-\lambda I| = (\lambda-8)(\lambda-18)$.
        \begin{align*}
            \lambda_1 &= 8 & \lambda_2 &= 18\\
            x_1 &=
            \begin{bmatrix}
                1\\
                1\\
            \end{bmatrix}&
            x_2 &=
            \begin{bmatrix}
                -1\\
                1\\
            \end{bmatrix}
        \end{align*}
        \item Let $
            y=
            \begin{bmatrix}
                x'\\
                y'\\
            \end{bmatrix}
        $, $
            y^\T\Lambda y =
            \begin{bmatrix}
                x' & y'\\
            \end{bmatrix}
            \begin{bmatrix}
                8 & 0\\
                0 & 18\\
            \end{bmatrix}
            \begin{bmatrix}
                x'\\
                y'\\
            \end{bmatrix}
            =72
        $.
        \item $8(x')^2+18(y')^2=72$.
        \item $\left( \frac{x'}{3} \right)^2+\left( \frac{y'}{2} \right)^2=1$.
    \end{itemize}
    \item Sidenote on rotation matrices:
    \begin{itemize}
        \item No rotation (rotates $
            \begin{bmatrix}
                0^\circ & 0^\circ\\
                0^\circ & 0^\circ\\
            \end{bmatrix}
        $): $
            \begin{bmatrix}
                1 & 0\\
                0 & 1\\
            \end{bmatrix}
            =
            \begin{bmatrix}
                \cos\theta & -\sin\theta\\
                \sin\theta & \cos\theta\\
            \end{bmatrix}
        $
        \begin{itemize}
            \item Identity matrix is special case of rotation matrix when $\theta=0^\circ$.
        \end{itemize}
        \item Any rotation matrix has $|R|=1$ because otherwise, it would do something to the size.
    \end{itemize}
    \item Back with the example:
    \begin{itemize}
        \renewcommand{\arraystretch}{1.6}
        \item $
            Q =
            \begin{bmatrix}
                \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}}\\
                \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}\\
            \end{bmatrix}
        $
        \renewcommand{\arraystretch}{1}
        \item $|Q|=1$.
        \item When $Q$ is set equivalent to the general rotation matrix (above), it is shown that $\theta=\frac{\pi}{4}$.
        \begin{center}
            \begin{tikzpicture}
                \draw (-2,0) -- (2,0) node[right]{$x$};
                \draw (0,-2) -- (0,2) node[above]{$y$};

                \draw [dashed] (-2,-2) -- (2,2) node[right]{$x'$};
                \draw [dashed] (2,-2) -- (-2,2) node[left]{$y'$};

                \begin{scope}[
                    rotate=45
                ]
                    \foreach \x in {-1.5,-1,-0.5,0.5,1,1.5} {
                        \draw [blue,thick] (\x,-0.1) -- (\x,0.1);
                    }
                    \foreach \y in {-1,-0.5,0.5,1} {
                        \draw [blue,thick] (-0.1,\y) -- (0.1,\y);
                    }

                    \fill [blue] (-1.5,0) circle (2pt);
                    \fill [blue] (1.5,0) circle (2pt);
                    \fill [blue] (0,-1) circle (2pt);
                    \fill [blue] (0,1) circle (2pt);

                    \draw [blue,thick] ellipse (1.5cm and 1cm);
                \end{scope}
            \end{tikzpicture}
        \end{center}
        \item If the sign of $|Q|$ is wrong, flip the columns (flips the sign of the determinant).
        \renewcommand{\arraystretch}{1.8}
        \begin{center}
            \begin{tabular}{c|c|c|c}
                $\lambda$'s & $\lambda_1 = 8$, $\lambda_2 = 18$ & $\lambda_1 = 18$, $\lambda_2 = 8$ & $\lambda_1 = 18$, $\lambda_2 = 8$\\
                \hline
                $Q$ & $
                    \begin{bmatrix}
                        -\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}\\
                        -\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}}\\
                    \end{bmatrix}
                $ & $
                    \begin{bmatrix}
                        -\frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}}\\
                        \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}}\\
                    \end{bmatrix}
                $ & $
                    \begin{bmatrix}
                        \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}\\
                        -\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}}\\
                    \end{bmatrix}
                $\\
                \hline
                $\theta$ & $\frac{5\pi}{4}$ & $\frac{3\pi}{4}$ & $\frac{7\pi}{4}$\\
                \hline
                Graph & \tikz[scale=0.5]{
                    \draw (-2,0) -- (2,0);
                    \draw (0,-2) -- (0,2);
                    \draw [white] (0,2) -- (0,2.3);

                    \draw [dashed] (-1.41,-1.41) -- (1.41,1.41) node[right]{$x'$};
                    \draw [dashed] (1.41,-1.41) -- (-1.41,1.41) node[left]{$y'$};

                    \draw [thick,->] (0,1.2) arc[start angle=90,end angle=315,radius=1.2cm];
                    \draw [thick,->] (0.8,0) arc[start angle=0,end angle=225,radius=0.8cm];
                } & \tikz[scale=0.5]{
                    \draw (-2,0) -- (2,0);
                    \draw (0,-2) -- (0,2);
                    \draw [white] (0,2) -- (0,2.3);

                    \draw [dashed] (-1.41,-1.41) -- (1.41,1.41) node[right]{$y'$};
                    \draw [dashed] (1.41,-1.41) -- (-1.41,1.41) node[left]{$x'$};

                    \draw [thick,->] (0,1.2) arc[start angle=90,end angle=225,radius=1.2cm];
                    \draw [thick,->] (0.8,0) arc[start angle=0,end angle=135,radius=0.8cm];
                } & \tikz[scale=0.5]{
                    \draw (-2,0) -- (2,0);
                    \draw (0,-2) -- (0,2);
                    \draw [white] (0,2) -- (0,2.3);

                    \draw [dashed] (-1.41,-1.41) -- (1.41,1.41) node[right]{$y'$};
                    \draw [dashed] (1.41,-1.41) -- (-1.41,1.41) node[left]{$x'$};

                    \draw [thick,->] (0,1.2) arc[start angle=90,end angle=405,radius=1.2cm];
                    \draw [thick,->] (0.8,0) arc[start angle=0,end angle=315,radius=0.8cm];
                }\\
                \hline
                Eq. & $\left( \frac{x'}{3} \right)^2+\left( \frac{y'}{2} \right)^2=1$ & $\left( \frac{x'}{2} \right)^2+\left( \frac{y'}{3} \right)^2=1$ & $\left( \frac{x'}{2} \right)^2+\left( \frac{y'}{3} \right)^2=1$\\
            \end{tabular}
        \end{center}
    \end{itemize}
    \item Classification of symmetric matrices:
    \renewcommand{\arraystretch}{1.4}
    \begin{center}
        \begin{tabular}{l|c|c}
            Classification & $x^\T Ax$ & $\lambda$'s\\
            \hline
            Positive definite & $f=x^\T Ax$, $f>0$ & All $\lambda\text{'s}>0$\\
            \hline
            Positive semidefinite & $f\geq 0$ & All $\lambda\text{'s}\geq0$\\
            \hline
            Negative definite & $f<0$ & All $\lambda\text{'s}<0$\\
            \hline
            Negative semidefinite & $f\leq 0$ & All $\lambda\text{'s}\leq0$\\
            \hline
            Indefinite & $f$ is positive and negative & $\lambda\text{'s}\in\R$\\
        \end{tabular}
    \end{center}
\end{itemize}



\section*{Nondiagonalizable Matrices}
\subsection*{Perturbations}
\begin{itemize}
    \item \marginnote{2/26:}If it's nondiagonalizable, how can we get it to as close to diagonalizable as possible? If that doesn't help, how can we get it into a useful form?
    \begin{equation*}
        A=
        \begin{bmatrix}
            1 & 1\\
            0 & 1\\
        \end{bmatrix}
    \end{equation*}
    \item $A$ is nondiagonalizable because the eigenvalues are sitting on the principal diagonal already, and they're the same. We want distinct eigenvalues.
    \item Let $\epsilon$ be a very small, approaching zero quantity.
    \begin{equation*}
        A_\epsilon =
        \begin{bmatrix}
            1 & 1\\
            \epsilon^2 & 1\\
        \end{bmatrix}
    \end{equation*}
    \begin{itemize}
        \item Choice of $\epsilon^2$ vs. $\epsilon$ helps when diagonalizing.
        \begin{align*}
            0 &= |A_\epsilon-\lambda I|\\
            &=
            \begin{vmatrix}
                1-\lambda & 1\\
                \epsilon^2 & 1-\lambda\\
            \end{vmatrix}\\
            &= (1-\lambda)^2-\epsilon^2\\
            &= 1-2\lambda+\lambda^2-\epsilon^2\\
            &= \lambda^2-2\lambda+(1-\epsilon)^2\\
            &= (\lambda-(1+\epsilon))(\lambda-(1-\epsilon))
        \end{align*}
        \item Quadratic formula may be helpful for factoring.
        \item Alternatively, think of it as a kind of difference of squares with a middle component.
    \end{itemize}
    \begin{align*}
        \lambda_1 &= 1+\epsilon & \lambda_2 &= 1-\epsilon
    \end{align*}
    \item $
        A_\epsilon-\lambda_1 I =
        \begin{bmatrix}
            -\epsilon & 1\\
            \epsilon^2 & -\epsilon\\
        \end{bmatrix}
    $, $
        x_1 =
        \begin{bmatrix}
            1\\
            \epsilon\\
        \end{bmatrix}
    $
    \item $
        A_\epsilon-\lambda_2 I =
        \begin{bmatrix}
            \epsilon & 1\\
            \epsilon^2 & \epsilon\\
        \end{bmatrix}
    $, $
        x_2 =
        \begin{bmatrix}
            1\\
            -\epsilon\\
        \end{bmatrix}
    $
    \item Find $S^{-1}$.
    \begin{itemize}
        \item $
            S^{-1} = \frac{1}{|S|}C^\T = -\frac{1}{2\epsilon}
            \begin{bmatrix}
                -\epsilon & -1\\
                -\epsilon & 1\\
            \end{bmatrix}
        $
    \end{itemize}
    \item $
        A_\epsilon = S\Lambda S^{-1} = -\frac{1}{2\epsilon}
        \begin{bmatrix}
            1 & 1\\
            \epsilon & -\epsilon\\
        \end{bmatrix}
        \begin{bmatrix}
            1+\epsilon & 0\\
            0 & 1-\epsilon\\
        \end{bmatrix}
        \begin{bmatrix}
            -\epsilon & -1\\
            -\epsilon & 1\\
        \end{bmatrix}
    $
    \item $
        A_\epsilon^n = -\frac{1}{2\epsilon}
        \begin{bmatrix}
            1 & 1\\
            \epsilon & -\epsilon\\
        \end{bmatrix}
        \begin{bmatrix}
            (1+\epsilon)^n & 0\\
            0 & (1-\epsilon)^n\\
        \end{bmatrix}
        \begin{bmatrix}
            -\epsilon & -1\\
            -\epsilon & 1\\
        \end{bmatrix}
    $
    \item Goal: In $A$, $\epsilon^2=0$. So we want $\lim_{\epsilon\to 0}A_\epsilon^n$.
    \begin{align*}
        \lim_{\epsilon\to 0} A_\epsilon^n &= \lim_{\epsilon\to 0} -\frac{1}{2\epsilon}
        \begin{bmatrix}
            1 & 1\\
            \epsilon & -\epsilon\\
        \end{bmatrix}
        \begin{bmatrix}
            (1+\epsilon)^n & 0\\
            0 & (1-\epsilon)^n\\
        \end{bmatrix}
        \begin{bmatrix}
            -\epsilon & -1\\
            -\epsilon & 1\\
        \end{bmatrix}\\
        &= \lim_{\epsilon\to 0} -\frac{1}{2\epsilon}
        \begin{bmatrix}
            1 & 1\\
            \epsilon & -\epsilon\\
        \end{bmatrix}
        \begin{bmatrix}
            -\epsilon(1+\epsilon)^n & -(1+\epsilon)^n\\
            -\epsilon(1-\epsilon)^n & (1-\epsilon)^n\\
        \end{bmatrix}\\
        &= \lim_{\epsilon\to 0} -\frac{1}{2\epsilon}
        \begin{bmatrix}
            -\epsilon(1+\epsilon)^n-\epsilon(1-\epsilon)^n & -(1+\epsilon)^n+(1-\epsilon)^n\\
            -\epsilon^2(1+\epsilon)^n+\epsilon^2(1-\epsilon)^n & -\epsilon(1+\epsilon)^n-\epsilon(1-\epsilon)^n\\
        \end{bmatrix}\\
        &= \lim_{\epsilon\to 0}
        \renewcommand{\arraystretch}{1.6}
        \begin{bmatrix}
            \frac{(1+\epsilon)^n+(1-\epsilon)^n}{2} & \frac{(1+\epsilon)^n-(1-\epsilon)^n}{2\epsilon}\\
            \frac{\epsilon(1+\epsilon)^n-\epsilon(1-\epsilon)^n}{2} & \frac{(1+\epsilon)^n+(1-\epsilon)^n}{2}\\
        \end{bmatrix}\\
        &=
        \begin{bmatrix}
            1 & \lim_{\epsilon\to 0} \frac{(1+\epsilon)^n-(1-\epsilon)^n}{2\epsilon}\\
            0 & 1\\
        \end{bmatrix}
    \end{align*}
    \begin{itemize}
        \item Use L'H\^{o}pital's rule for the last limit.
        \begin{align*}
            \dd{\epsilon}\left( (1+\epsilon)^n-(1-\epsilon)^n \right) &= \dd{\epsilon}(1+\epsilon)^n-\dd{\epsilon}(1-\epsilon)^n\\
            &= n(1+\epsilon)^{n-1}\dd{\epsilon}(1+\epsilon)-n(1-\epsilon)^{n-1}\dd{\epsilon}(1-\epsilon)\\
            &= n(1+\epsilon)^{n-1}(1)-n(1-\epsilon)^{n-1}(-1)\\
            &= n(1+\epsilon)^{n-1}+n(1-\epsilon)^{n-1}\\
            &= n\left( (1+\epsilon)^{n-1}+(1-\epsilon)^{n-1} \right)
        \end{align*}
        \begin{align*}
            \lim_{\epsilon\to 0} \frac{(1+\epsilon)^n-(1-\epsilon)^n}{2\epsilon} &= \lim_{\epsilon\to 0} \frac{n\left( (1+\epsilon)^{n-1}+(1-\epsilon)^{n-1} \right)}{2}\\
            &= \frac{2n}{2}\\
            &= n
        \end{align*}
        \item Thus, we find the following final formula for $A^n$.
        \begin{equation*}
            A^n =
            \begin{bmatrix}
                1 & n\\
                0 & 1\\
            \end{bmatrix}
        \end{equation*}
    \end{itemize}
\end{itemize}


\subsection*{Jordan Canonical Form}
\begin{itemize}
    \item \marginnote{2/27:}If $A$ is diagonalizable, $A=S\Lambda S^{-1}$.
    \begin{itemize}
        \item $
            \Lambda=
            \begin{bmatrix}
                \lambda_1 & & & 0\\
                 & \lambda_2 & & \\
                 & & \ddots & \\
                0 & & & \lambda_n\\
            \end{bmatrix}
        $
    \end{itemize}
    \item If $A$ is nondiagonalizable, $A=MJM^{-1}$$^[$\footnote{$J$ for Jordan matrix.}$^]$.
    \begin{itemize}
        \item $
            J=
            \begin{bmatrix}
                \lambda_1 & 1 & & 0\\
                 & \lambda_2 & &\\
                 &  & \ddots & 1\\
                0 &  &  & \lambda_n\\
            \end{bmatrix}
        $
        \item You are only allowed to have some 1s directly above the principal diagonal.
        \item Example: $
            J =
            \begin{bmatrix}
                \lambda_1 & 1\\
                0 & \lambda_2\\
            \end{bmatrix}
        $
        \item Example: $
            J =
            \begin{bmatrix}
                \lambda_1 & 0 & 0\\
                0 & \lambda_2 & 1\\
                0 & 0 & \lambda_3\\
            \end{bmatrix}
        $
        \item Note that if a Jordan form factorization is necessary, at least two $\lambda_1$, $\lambda_2$, and $\lambda_3$ are the same value. 
    \end{itemize}
\end{itemize}
\begin{tchart}{1.4}{Eigenvectors}{Generalized Eigenvectors / Power Vectors}
    $Ax=\lambda x$ & $(A-\lambda I)^px_m=0$\\
    $(A-\lambda I)x_s=0$ &\\
    $x_s$ is an eigenvector. &\\
\end{tchart}
\vspace{1em}
\begin{equation*}
    A=
    \begin{bmatrix}
        2 & 1\\
        0 & 2\\
    \end{bmatrix}
\end{equation*}
\begin{itemize}
    \item $\lambda_1=\lambda_2=2$.
    \item $
        A-2I =
        \begin{bmatrix}
            0 & 1\\
            0 & 0\\
        \end{bmatrix}
    $, so $
        x_1 =
        \begin{bmatrix}
            1\\
            0\\
        \end{bmatrix}
    $. This is an eigenvector.
    \item Now, note that $A-\lambda I$ raised to a power $p$ will eventually have a null space different from that of $A-\lambda I$ for some $p>1$ and $p\in\mathbb{N}$.
    \begin{itemize}
        \item Also note that $p\leq n$ for an $n$-square matrix.
        \item This implies that there exists a power vector distinct from the eigenvector(s) for some power $p$.
    \end{itemize}
    \item Let's find that power vector.
    \item $
        (A-2I)^2 =
        \begin{bmatrix}
            0 & 0\\
            0 & 0\\
        \end{bmatrix}
    $, so we can define a power vector $
        x_2 =
        \begin{bmatrix}
            0\\
            1\\
        \end{bmatrix}
    $. This P.V. has degree 2.
    \item Note that $A$ is already a Jordan matrix, so it makes sense that the eigenvectors/power vectors form the identity matrix. In other words, $M=M^{-1}=I_2$.
    \item Let's try another, less immediately clear example.
    \begin{equation*}
        A=
        \begin{bmatrix}
            3 & 1\\
            -1 & 1\\
        \end{bmatrix}
    \end{equation*}
    \item Since $A$ is neither upper triangular nor diagonal, we must derive the characteristic polynomial to find the eigenvectors.
    \begin{align*}
        0 &= |A-\lambda I|\\
        &= (3-\lambda)(1-\lambda)+1\\
        &= \lambda^2-4\lambda+4\\
        &= (\lambda-2)^2
    \end{align*}
    \begin{equation*}
        \lambda_1=\lambda_2=2
    \end{equation*}
    \item Since the algebraic multiplicity is 2 and the geometric multiplicity is only 1, find the one possible eigenvector.
    \begin{itemize}
        \item $
            A-2I=
            \begin{bmatrix}
                1 & 1\\
                -1 & -1\\
            \end{bmatrix}
        $, so $
            x_1 =
            \begin{bmatrix}
                1\\
                -1\\
            \end{bmatrix}
        $. This is an E.V.
    \end{itemize}
    \item We can also find a power vector.
    \begin{itemize}
        \item $
            (A-2I)^2 =
            \begin{bmatrix}
                0 & 0\\
                0 & 0\\
            \end{bmatrix}
        $, so $
            x_2=
            \begin{bmatrix}
                1\\
                0\\
            \end{bmatrix}
        $. This is a P.V. of degree 2.
    \end{itemize}
    \item We know that $Ax_1=2x_1$. However, in order to finish finding $J$, we need to (the reason will soon become clear) find $Ax_2$ in terms of $x_2$ and/or $x_1$. This can be done as follows.
    \begin{align*}
        (A-2I)^2x_2 &= 0\\
        (A-2I)(A-2I)x_2 &= (A-2I)x_1\\
        (A-2I)x_2 &= x_1\\
        Ax_2-2Ix_2 &= x_1\\
        Ax_2-2x_2 &= x_1\\
        Ax_2 &= x_1+2x_2
    \end{align*}
    \begin{itemize}
        \item Alternatively, we can think of starting from $(A-2I)x_2=x_1$ because we need to introduce the coefficient of 1 for one of the eigenvectors somehow.
        \item What combination of $A-\lambda I$ gives us another eigenvector?
    \end{itemize}
    \item Combine this result with $Ax_1=2x_1$ to yield the following set of equations.
    \begin{align*}
        Ax_1 &= 2x_1+0x_2\\
        Ax_2 &= x_1+2x_2
    \end{align*}
    \item Express the set of equations above explicitly in terms of the matrices that the variables represent.
    \begin{align*}
        \begin{bmatrix}
            3 & 1\\
            -1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            1\\
            -1\\
        \end{bmatrix}
        &= 2
        \begin{bmatrix}
            1\\
            -1\\
        \end{bmatrix}
        +0
        \begin{bmatrix}
            1\\
            0\\
        \end{bmatrix}\\
        \begin{bmatrix}
            3 & 1\\
            -1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            1\\
            0\\
        \end{bmatrix}
        &= 1
        \begin{bmatrix}
            1\\
            -1\\
        \end{bmatrix}
        +2
        \begin{bmatrix}
            1\\
            0\\
        \end{bmatrix}
    \end{align*}
    \item Rewrite the right side of the above set of equations to condense linear operations into matrix multiplication.
    \begin{align*}
        \begin{bmatrix}
            3 & 1\\
            -1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            1\\
            -1\\
        \end{bmatrix}
        &=
        \begin{bmatrix}
            1 & 1\\
            -1 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
            2\\
            0\\
        \end{bmatrix}\\
        \begin{bmatrix}
            3 & 1\\
            -1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            1\\
            0\\
        \end{bmatrix}
        &=
        \begin{bmatrix}
            1 & 1\\
            -1 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
            1\\
            2\\
        \end{bmatrix}
    \end{align*}
    \item Combine the two equations into one, giving $AM=MJ$.
    \begin{equation*}
        \begin{bmatrix}
            3 & 1\\
            -1 & 1\\
        \end{bmatrix}
        \begin{bmatrix}
            1 & 1\\
            -1 & 0\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            1 & 1\\
            -1 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
            2 & 1\\
            0 & 2\\
        \end{bmatrix}
    \end{equation*}
    \item Now, we have the Jordan matrix (the rightmost matrix above).
    \item Note that the following algebra would give us the $MJM^{-1}$ factorization of $A$.
    \begin{align*}
        AM &= MJ\\
        AMM^{-1} &= MJM^{-1}\\
        A &= MJM^{-1}
    \end{align*}
    \item Also note that if we find a coefficient matrix from the original set of equations and transpose it, we will get the Jordan matrix:
    \begin{equation*}
        \begin{bmatrix}
            2 & 0\\
            1 & 2\\
        \end{bmatrix}^\T
        = J =
        \begin{bmatrix}
            2 & 1\\
            0 & 2\\
        \end{bmatrix}
    \end{equation*}
    \item Let's try a bigger example.
    \begin{equation*}
        A=
        \begin{bmatrix}
            3 & 0 & 0\\
            0 & 4 & -1\\
            0 & 1 & 2\\
        \end{bmatrix}
    \end{equation*}
    \item $\lambda_1=\lambda_2=\lambda_3=3$
    \item $\text{A.M.}=3$, $\text{G.M.}=2$.
    \item $
        A-3I=
        \begin{bmatrix}
            0 & 0 & 0\\
            0 & 1 & -1\\
            0 & 1 & -1\\
        \end{bmatrix}
    $
    \item $
        x_1=
        \begin{bmatrix}
            1\\
            0\\
            0\\
        \end{bmatrix}
    $, $
        x_2=
        \begin{bmatrix}
            0\\
            1\\
            1\\
        \end{bmatrix}
    $
    \item Because $(A-3I)^2=0_3$ and because of the equivalence outlined in the previous example, we can use one of the following to find an $x_3$ that will suit out needs.
    \begin{itemize}
        \item $
            \begin{bmatrix}
                0 & 0 & 0\\
                0 & 1 & -1\\
                0 & 1 & -1\\
            \end{bmatrix}
            \begin{bmatrix}
                |\\
                x_3\\
                |\\
            \end{bmatrix}
            =
            \begin{bmatrix}
                1\\
                0\\
                0\\
            \end{bmatrix}
        $ or $
            \begin{bmatrix}
                0 & 0 & 0\\
                0 & 1 & -1\\
                0 & 1 & -1\\
            \end{bmatrix}
            \begin{bmatrix}
                |\\
                x_3\\
                |\\
            \end{bmatrix}
            =
            \begin{bmatrix}
                0\\
                1\\
                1\\
            \end{bmatrix}
        $
    \end{itemize}
    \item The first option will not work because no $x_3$ vector can get a 1 in the top position of $x_1$.
    \item For the second one, use inspection: $
        \begin{bmatrix}
            0 & 0 & 0\\
            0 & 1 & -1\\
            0 & 1 & -1\\
        \end{bmatrix}
        \begin{bmatrix}
            0\\
            1\\
            0\\
        \end{bmatrix}
        =
        \begin{bmatrix}
            0\\
            1\\
            1\\
        \end{bmatrix}
    $
    \begin{itemize}
        \item $x_3$ must be a power vector of $A-3I$ and must be independent of $x_1$ and $x_2$, so that $M$ is invertible.
    \end{itemize}
    \item Find $Ax_3$ in terms of $x_1$, $x_2$, and $x_3$.
    \begin{itemize}
        \item $(A-3I)x_3=x_2 \Rightarrow Ax_3-3x_3=x_2 \Rightarrow Ax_3=x_2+3x_3$.
    \end{itemize}
    \item Write the three equations as a set.
    \begin{align*}
        Ax_1 &= 3x_1+0x_2+0x_3\\
        Ax_2 &= 0x_1+3x_2+0x_3\\
        Ax_3 &= 0x_1+1x_2+3x_3
    \end{align*}
    \item Instead of going through converting this set of equations to matrix equations, simply take a coefficient matrix and transpose it to find $J$:
    \begin{itemize}
        \item $
            J=
            \begin{bmatrix}
                3 & 0 & 0\\
                0 & 3 & 1\\
                0 & 0 & 3\\
            \end{bmatrix}
        $
    \end{itemize}
    \item $
        A=MJM^{-1}=
        \begin{bmatrix}
            1 & 0 & 0\\
            0 & 1 & 1\\
            0 & 1 & 0\\
        \end{bmatrix}
        \begin{bmatrix}
            3 & 0 & 0\\
            0 & 3 & 1\\
            0 & 0 & 3\\
        \end{bmatrix}
        \begin{bmatrix}
            1 & 0 & 0\\
            0 & 0 & 1\\
            0 & 1 & -1\\
        \end{bmatrix}
    $
    \item Raising $J^n$ is easier than raising $A^n$, but it's still not easy.
\end{itemize}




\end{document}